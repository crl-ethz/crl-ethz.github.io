@article{inverse-design-for-robotic-assembly,
  title={Inverse Design for Robotic Assembly via Task and Motion Planning},
  author={Huang, Yijiang and Fadini, Gabriele},
  journal={task-and-motion-planning, robotic-assembly, inverse-design, co-design},
  year={2025},
  abstract={Can we optimize a design so that a robot can assemble it more easily? This project explores inverse design for robotic assembly using task and motion planning (TAMP), coupling design optimization with planning algorithms that lays the foundation for designing robot-friendly structures.},
  pdf={2025_inverse-design-for-robotic-assembly.pdf},
  website={/inverse-design-for-robotic-assembly/},
  preview={2025_inverse_design_w_tamp.png},
  selected={true},
}
@article{trajectory-optimization-and-policy-distillation,
  title={Trajectory Optimization and Policy Distillation for Agile Control of Hybrid Mobile Robots},
  author={Jin Cheng and Stelian Coros},
  journal={bipedal-locomotion, trajectory-optimization, model-predictive-control, policy-distillation},
  year={2025},
  abstract={Hybrid mobile robots that integrate wheels and legs present a promising locomotion paradigm, combining the speed and efficiency of wheeled motion with the adaptability of legged systems. However, controlling such platforms remains challenging due to their underactuated and hybrid dynamics. This project explores a control-learning framework that leverages trajectory optimization (TO) or model predictive control (MPC) to generate high-quality motion plans while concurrently distilling a lightweight neural policy through supervised learning. The approach supports both sampling-based and gradient-based optimization methods, depending on simulator capabilities, and emphasizes real-world learning by collecting rollout data directly from hardware. The resulting policy enables efficient and robust control suitable for deployment under real-time constraints. Development and evaluation will be conducted using the LIMX Dynamics TRON1 robot, a bipedal wheeled platform with 4 DoF per leg, providing a rich testbed for advancing agile and intelligent control in hybrid robotic systems.},
  pdf={2025_Trajectory_Optimization_and_Policy_Distillation_for_Agile_Control_of_Hybrid_Mobile_Robots.pdf},
  website={https://sirop.org/app/a873b81c-fdb5-4c4c-b9a2-c93efe4f6f9a},
  preview={2025_toapd.png},
  selected={true},
}
@article{mp-for-active-env-manip,
  title={Robotic motion planning for active environmental manipulation},
  author={Hartmann, Valentin and Huang, Yijiang},
  journal={motion-planning, physics-simulation, mobile-manipulation},
  year={2025},
  pdf={2025_mp_for_active_env_manip.pdf},
  abstract={Robotic motion planning typically assumes static, explicitly defined environments, limiting a robot's operational capabilities. This project explores how robots can actively modify their surroundings to dynamically extend their workspace. By integrating physics-based simulation with sampling-based motion planning techniques, we aim to enable flexible mobile manipulation in changing environments.},
  website={/mp-for-active-env-manip/},
  preview={2025_mp-for-active-env-manip.png},
  selected={true},
}
@article{stra-humanoid-box-lifting,
  title={Strategic Humanoid Box Lifting},
  author={Cheng, Jin and Huang, Yijiang and An, Tianxu},
  journal={reinforcement-learning, trajectory-optimization, humanoid, contact-rich-manipulation},
  year={2025},
  pdf={2025_stra-humanoid-box-lifting.pdf},
  abstract={Manipulating large, heavy objects without convenient grasp affordances poses a significant challenge for humanoid robots. This project develops a demonstration-guided reinforcement learning framework enabling a humanoid robot to strategically lift unwieldy objects through coordinated full-body motion.},
  website={/stra-humanoid-box-lifting/},
  preview={2025_stra-humanoid-box-lifting.png},
  selected={true},
}
